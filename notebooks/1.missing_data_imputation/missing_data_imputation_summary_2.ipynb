{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining feature engineering and modeling fitting (ColumnTransformer vs. Pipeline)\n",
    "\n",
    "<span>Photo by <a href=\"https://unsplash.com/@spacexuan?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Crystal Kwok</a> on <a href=\"https://unsplash.com/s/photos/pipes?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Unsplash</a></span>\n",
    "\n",
    "In the previous post, we learned about various missing data imputation strategies using scikit-learn. Before we dive into how we automatically determine the best imputation method for a given problem, I would like to first touch on two scikit-learn classes, `ColumnTransformer` and `Pipeline`, and the differences between them. \n",
    "\n",
    "Both `ColumnTransformer` and `Pipeline` are used to combine different feature engineering steps (e.g. missing data imputation, categorical variable encoding, feature scaling, etc.) to transform data before feeding it into a model, but there are two major differences between them:\n",
    "\n",
    "\n",
    "**1. `ColumnTransformer` is only for transformers vs. `Pipeline` is for both transformers and estimator**   \n",
    "**2. `ColumnTransformer` is parallel vs. `Pipeline` is sequential**\n",
    "\n",
    "\n",
    "First of all, what do I mean by transformer and estimator? \n",
    "\n",
    "Second, what do I mean by parallel vs. sequential? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data\n",
    "\n",
    "Let's first prepare the [house price data from Kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data) we will be using in this post. It is the same data used in the previous post as well. Do not forget to split the data into train and test sets before performing any feature engineering steps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# preparing data \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feature engineering: imputation, scaling, encoding\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# putting together in pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# model selection\n",
    "from sklearn.linear_model import Lasso, LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 79), (438, 79))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import house price data \n",
    "df = pd.read_csv('../data/house_price/train.csv', index_col='Id')\n",
    "\n",
    "# numerical columns vs. categorical columns \n",
    "num_cols = df.drop('SalePrice', axis=1).select_dtypes('number').columns\n",
    "cat_cols = df.drop('SalePrice', axis=1).select_dtypes('object').columns\n",
    "\n",
    "# split train and test dataset \n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('SalePrice', axis=1), \n",
    "                                                    df['SalePrice'], \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=0)\n",
    "\n",
    "# check the size of train and test data\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "Now that we have the data ready, let's say we want to train a model using Lasso regression that predicts `SalePrice` using the variables we have. Instead of using all of the 79 variables, let's use only numerical variables this time (we will include the categorical variables in the next section). We already know there is plenty of missing data in some columns as we saw in the previous post (e.g. `LotFrontage`, `MasVnrArea`, and `GarageYrBlt` among numerical columns), we definitely want to perform missing data imputation before fitting a model. Also, let's say we also want to scale the data using `StandardScaler`. The following is what we would do normally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8419801151434141"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take only numerical data\n",
    "X_temp = X_train[num_cols].copy()\n",
    "\n",
    "# missing data imputation\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_impute = imputer.fit_transform(X_temp)  # np.ndarray\n",
    "X_impute = pd.DataFrame(X_impute, columns=X_temp.columns)  # pd.DataFrame\n",
    "\n",
    "\n",
    "# scale data \n",
    "scaler = StandardScaler()\n",
    "X_scale = scaler.fit_transform(X_impute)  # np.ndarray\n",
    "X_scale = pd.DataFrame(X_scale, columns=X_temp.columns)  # pd.DataFrame\n",
    "\n",
    "# fit model \n",
    "lasso = Lasso()\n",
    "lasso.fit(X_scale, y_train)\n",
    "lasso.score(X_scale, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great but there are manual steps for moving transformed data: we have to pass the output of the first step (`SimpleImputer`) to the second step (`StandardScaler`) as an input. And then, the output of the second step (`StandardScaler`) is passed to the third step (`Lasso`) as an input. If we have more feature engineering steps, it will be more complex to handle different inputs and outputs. So, here comes Pipeline to the rescue!\n",
    "\n",
    "**Pipeline is a class with wich you can put transformers and an estimator (model) together as sequential steps**. You just need to pass a list of tuples of steps in this order: (step_name, transformer or estimator object). Let's rewrite the same flow abouve in Pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8419801151434141"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('imputer', SimpleImputer(strategy='mean')),\n",
    "                 ('scaler', StandardScaler()),\n",
    "                 ('lasso', Lasso())])\n",
    "\n",
    "pipe.fit(X_temp, y_train)\n",
    "pipe.score(X_temp, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We saved a lot more lines and it looks much cleaner! As you can see, **Pipeline passes the first step's output to the next step as its input, meaning Pipeline is sequential**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ColumnTransformer\n",
    "\n",
    "Now let's go back to our original dataset where we have both numerical and categorical variables. Because we cannot apply mean imputation to categorical variables, we decide to use mode imputation for categorical variables and mean imputation for numerical imputation. Okay, then can we do something like this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('num_imputer', SimpleImputer(strategy='mean')),\n",
    "                 ('cat_imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                 ('lasso', Lasso())])\n",
    "\n",
    "# pipe.fit throws an error\n",
    "# ------\n",
    "# ValueError: Cannot use mean strategy with non-numeric data:\n",
    "# could not convert string to float: 'RL'\n",
    "# ------\n",
    "\n",
    "# pipe.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, no! When `pipe` fits `SimpleImputer(strategy='mean')` to X_train, which has both numerical and categorical, it fails because `SimpleImputer(strategy='mean')` can only apply to numerical variables. So, we need to let our pipeline know that we want to apply mean imputation to only numerical variables and most_frequent imputation to categorical variables. \n",
    "\n",
    "How do we do that? With `ColumnTransformer`! \n",
    "\n",
    "`ColumnTransformer` is similar to `Pipeline` in a sense that you pass a list of (step_name, transformer class) tuples, but in this time, you pass another argument in the tuple which is column names you want to apply the transformer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ColumnTransformer([('numerical', SimpleImputer(strategy='mean'), num_cols)])\n",
    "\n",
    "# fit\n",
    "X_train_transformed = transformer.fit_transform(X_train)\n",
    "X_train_transformed = pd.DataFrame(X_train_transformed, columns=num_cols)\n",
    "\n",
    "X_train_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you may have noticed that the output columns are not the full columns of the DataFrame you passed in, it's only columns that you used for transformer.\n",
    "\n",
    "This time, let's put both transformers together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying different transformers to different columns \n",
    "transformer = ColumnTransformer(\n",
    "    [('numerical', SimpleImputer(strategy='mean'), num_cols), \n",
    "     ('categorical', SimpleImputer(strategy='most_frequent'), cat_cols)])\n",
    "\n",
    "\n",
    "transformer.fit(X_train)\n",
    "X_train_transformed = transformer.transform(X_train)\n",
    "X_train_transformed = pd.DataFrame(X_train_transformed, \n",
    "                                   columns=list(num_cols) + list(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the output columns are `list(num_cols) + list(cat_cols)` which is different from the original column order. **Remember the output columns are the concatenated outputs of each step in ColumnTransformer**. \n",
    "\n",
    "This is still very handy that you can just use a few lines of code to perform multiple feature engineering steps.\n",
    "\n",
    "If you have other transformers, e.g. StandardScaler, you cannot do this because the output columns are not more than X_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying different transformers to different columns \n",
    "transformer = ColumnTransformer(\n",
    "    [('numerical', SimpleImputer(strategy='mean'), num_cols), \n",
    "     ('categorical', SimpleImputer(strategy='most_frequent'), cat_cols)])\n",
    "\n",
    "\n",
    "transformer.fit(X_train)\n",
    "X_train_transformed = transformer.transform(X_train)\n",
    "X_train_transformed = pd.DataFrame(X_train_transformed, \n",
    "                                   columns=list(num_cols) + list(cat_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then how do we apply multiple steps to a set of columns and a different steps to a different set of columns? \n",
    "\n",
    "We use `Pipeline` again!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_pipeline= Pipeline([('imputer', SimpleImputer(strategy='mean')),\n",
    "                        ('scaler', StandardScaler())])\n",
    "\n",
    "cat_pipeline = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                        ('encoder', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor_pipe = ColumnTransformer([(\"num_pipeline\", num_pipeline, num_cols),\n",
    "                                 (\"cat_pipeline\", cat_pipeline, cat_cols)])\n",
    "\n",
    "preprocessor_pipe.fit(X_train)\n",
    "X_train_imputed = preprocessor_pipe.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference between Pipeline vs. ColumnTransformer:\n",
    "\n",
    "Pipeline \n",
    "- passes the output of the first transformer to the next one\n",
    "- Sequential\n",
    "- No option to pass which columns to apply transformers\n",
    "- Output will be the same shape of the original input shape\n",
    "- Work with an estimator\n",
    "- fit, fit_transform, fit_predict, predict, score, etc.\n",
    "\n",
    "ColumnTransformer \n",
    "- ColumnTransformer treats each transformer independently. \n",
    "- Parallel\n",
    "- Can specify which column each transformer applies to \n",
    "- Output is concatenated array, concatenated after all steps. Size will can be different from input\n",
    "- The output column order will be the order of passed columns\n",
    "- Only for column transformation. No prediction\n",
    "- fit, fit_transform (no predict or score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-feature-engineering",
   "language": "python",
   "name": "venv-feature-engineering"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
