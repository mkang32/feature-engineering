{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining feature engineering and modeling fitting (Pipeline vs. ColumnTransformer)\n",
    "\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"images/pipeline_unsplash.jpg\" alt=\"drawing\" width=\"400\"/>\n",
    "<figcaption>Photo by <a href=\"https://unsplash.com/@spacexuan?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Crystal Kwok</a> on <a href=\"https://unsplash.com/s/photos/pipes?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText\">Unsplash</a></figcaption>\n",
    "</div>\n",
    "\n",
    "In the previous post, we learned about various missing data imputation strategies using scikit-learn. Before diving into finding the best imputation method for a given problem, I would like to first introduce two scikit-learn classes, `Pipeline` and `ColumnTransformer` . \n",
    "\n",
    "Both `Pipeline` and `ColumnTransformer` are used to combine different transformers (i.e. feature engineering steps such as `SimpleImputer` and `OneHotEncoder`) to transform data. However, there are two major differences between them:\n",
    "\n",
    "\n",
    "**1. `Pipeline` can be used for both/either of transformer and estimator (model) vs. `ColumnTransformer` is only for transformers**   \n",
    "**2. `Pipeline` is sequential vs. `ColumnTransformer` is parallel/independent**\n",
    "\n",
    "Don't worry if this sounds too complicated! I will walk you through what I mean by the above statements with code examples. I had a lot of fun while digging into these two classes, so I hope you enjoy and find it useful at the end as well! \n",
    "\n",
    "# Table of Conents\n",
    "0. [Prepare Data](#prep)\n",
    "1. [Put Transformers and Estimator Together: Pipeline](#pipeline)\n",
    "2. [Apply Transformers to Different Columns: ColumnTransformer](#columntransformer)\n",
    "3. [Separate Feature Engineering Pipelines for Numerical and Categorical Variables](#separate)\n",
    "4. [Final Pipeline](#final)\n",
    "5. [Summary](#summary)\n",
    "6. [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=prep></a>\n",
    "# 0. Prepare Data\n",
    "\n",
    "Let's first prepare the [house price data from Kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data) we will be using in this post. The data is preprocessed by replacing `'?'` with `NaN`. Do not forget to split the data into train and test sets before performing any feature engineering steps to avoid data leakage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# preparing data \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# feature engineering: imputation, scaling, encoding\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# putting together in pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# model to use\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1022, 79), (438, 79))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import house price data \n",
    "df = pd.read_csv('../data/house_price/train.csv', index_col='Id')\n",
    "\n",
    "# numerical columns vs. categorical columns \n",
    "num_cols = df.drop('SalePrice', axis=1).select_dtypes('number').columns\n",
    "cat_cols = df.drop('SalePrice', axis=1).select_dtypes('object').columns\n",
    "\n",
    "# split train and test dataset \n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('SalePrice', axis=1), \n",
    "                                                    df['SalePrice'], \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=0)\n",
    "\n",
    "# check the size of train and test data\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9375</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2887</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>7207</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>50</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9060</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>30</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>8400</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Bnk</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "Id                                                                      \n",
       "65            60       RL          NaN     9375   Pave   NaN      Reg   \n",
       "683          120       RL          NaN     2887   Pave   NaN      Reg   \n",
       "961           20       RL         50.0     7207   Pave   NaN      IR1   \n",
       "1385          50       RL         60.0     9060   Pave   NaN      Reg   \n",
       "1101          30       RL         60.0     8400   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities LotConfig  ... ScreenPorch PoolArea PoolQC  Fence  \\\n",
       "Id                                    ...                                      \n",
       "65           Lvl    AllPub    Inside  ...           0        0    NaN  GdPrv   \n",
       "683          HLS    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "961          Lvl    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "1385         Lvl    AllPub    Inside  ...           0        0    NaN  MnPrv   \n",
       "1101         Bnk    AllPub    Inside  ...           0        0    NaN    NaN   \n",
       "\n",
       "     MiscFeature MiscVal  MoSold  YrSold  SaleType  SaleCondition  \n",
       "Id                                                                 \n",
       "65           NaN       0       2    2009        WD         Normal  \n",
       "683          NaN       0      11    2008        WD         Normal  \n",
       "961          NaN       0       2    2010        WD         Normal  \n",
       "1385         NaN       0      10    2009        WD         Normal  \n",
       "1101         NaN       0       1    2009        WD         Normal  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=pipeline></a>\n",
    "# 1. Put Transformers and an Estimator Together: Pipeline\n",
    "\n",
    "Let's say we want to train a Lasso regression model that predicts `SalePrice`. Instead of using all of the 79 variables we have, let's use only numerical variables this time. \n",
    "\n",
    "I already know there is plenty of missing data in some columns (e.g. `LotFrontage`, `MasVnrArea`, and `GarageYrBlt` among numerical columns), so we want to perform missing data imputation before fitting a model. Also, let's say we also want to scale the data using `StandardScaler` because the scale of variables is all different.\n",
    "\n",
    "This is what we would do normally to fit a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8419801151434141"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take only numerical data\n",
    "X_temp = X_train[num_cols].copy()\n",
    "\n",
    "# missing data imputation\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_impute = imputer.fit_transform(X_temp)  # np.ndarray\n",
    "X_impute = pd.DataFrame(X_impute, columns=X_temp.columns)  # pd.DataFrame\n",
    "\n",
    "# scale data \n",
    "scaler = StandardScaler()\n",
    "X_scale = scaler.fit_transform(X_impute)  # np.ndarray\n",
    "X_scale = pd.DataFrame(X_scale, columns=X_temp.columns)  # pd.DataFrame\n",
    "\n",
    "# fit model\n",
    "lasso = Lasso()\n",
    "lasso.fit(X_scale, y_train)\n",
    "lasso.score(X_scale, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great but we have to manually move data from one step to another: we pass the output of the first step (`SimpleImputer`) to the second step (`StandardScaler`) as an input (`X_impute`). And then, the output of the second step (`StandardScaler`) is passed to the third step (`Lasso`) as an input (`X_scale`). If we have more feature engineering steps, it will be more complex to handle different inputs and outputs. So, here `Pipeline` comes to the rescue!\n",
    "\n",
    "**With `Pipeline`, you can combine transformers and an estimator (model) together**. You can transform your data and then fit a model with the transformed data. You just need to pass a list of tuples defining the steps in order: (step_name, transformer or estimator object). Let's rewrite the same logic using `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8419801151434141"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define feature engineering and model together\n",
    "pipe = Pipeline([('imputer', SimpleImputer(strategy='mean')),\n",
    "                 ('scaler', StandardScaler()),\n",
    "                 ('lasso', Lasso())])\n",
    "\n",
    "# fit model\n",
    "pipe.fit(X_temp, y_train)\n",
    "pipe.score(X_temp, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We saved a lot of lines and it looks much cleaner and more understandable! As you can see, **Pipeline passes the first step's output to the next step as its input, meaning Pipeline is sequential**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=columntransformer></a>\n",
    "# 2. Apply Transformers to Different Columns: ColumnTransformer\n",
    "\n",
    "Let's go back to our original dataset where we had both numerical and categorical variables. Because we cannot apply mean imputation to categorical variables (there is no 'mean' in categories!), we would want to use something different. One of the commonly used techniques is mode imputation (filling with the most frequent category), so let's use that. \n",
    "\n",
    "Mean imputation for numerical variables and mode imputation for categorical variables - can we do this in Pipeline as below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we do this? \n",
    "pipe = Pipeline([('num_imputer', SimpleImputer(strategy='mean')),\n",
    "                 ('cat_imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                 ('lasso', Lasso())])\n",
    "\n",
    "# pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, no! If you run the above code, it will throw an error like this: \n",
    "\n",
    "```\n",
    "ValueError: Cannot use mean strategy with non-numeric data:\n",
    "could not convert string to float: 'RL'\n",
    "```\n",
    "\n",
    "The error happens when `Pipeline` attempts to apply mean imputation to all of the columns including a categorical variable that contains a string category called `'RL'`. Remember mean imputation can only be applied to numerical variables so our `SimpleImputer(strategy='mean')` freaked out! \n",
    "\n",
    "**We need to let our `Pipeline` know which columns to apply which transformer. How do we do that? We do it with `ColumnTransformer`!**\n",
    "\n",
    "`ColumnTransformer` is similar to `Pipeline` in the sense that you put transformers together as a list of tuples, but in this time, you pass one more argument: a list of the column names you want to apply a transformer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying different transformers to different columns \n",
    "transformer = ColumnTransformer(\n",
    "    [('numerical', SimpleImputer(strategy='mean'), num_cols), \n",
    "     ('categorical', SimpleImputer(strategy='most_frequent'), cat_cols)])\n",
    "\n",
    "# fit transformer with out train data\n",
    "transformer.fit(X_train)\n",
    "\n",
    "# transform the train data and create a DataFrame with the transformed data\n",
    "X_train_transformed = transformer.transform(X_train)\n",
    "X_train_transformed = pd.DataFrame(X_train_transformed, \n",
    "                                   columns=list(num_cols) + list(cat_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed we defined the output columns to be `list(num_cols) + list(cat_cols)`, not `X_train.columns`. This is because **`ColumnTransformer` fits each transformer independently in parallel and concatenates all of the outputs at the end**. \n",
    "\n",
    "That is, `ColumnTransformer` takes **only** numerical columns (`num_cols`), fits and transforms them using `SimpleImputer(strategy='mean')`, sets the output aside. At the same time, it does the same thing for categorical columns (`cat_cols`) with `SimpleImputer(strategy='most_frequent')`. When it is done with each and every step, it combines all of the two outputs in the order that the transformers are performed. Therefore, **be aware of the column orders because the final output may be different from your original DataFrame!**\n",
    "\n",
    "Note that `ColumnTransformer` can only be used for transformers, not estimators. We cannot include `Lasso()` and fit the model as we did with `Pipeline`. **`ColumnTransformer` is only used for data pre-processing, so there is no `predict` or `score` as in `Pipeline`**. To train a model and calculate a performance score, we will need `Pipeline` again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=separate></a>\n",
    "# 3. Separate Feature Engineering Pipelines for Numerical and Categorical Variables\n",
    "\n",
    "Let's go one step further and include more feature engineering steps. In addition to the missing data imputation, we also want to scale our numerical variables using `StandardScaler` and encode the categorical variables using `OneHotEncoder`. Can we do something like this then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can we do this? \n",
    "transformer = ColumnTransformer(\n",
    "    [('numerical_imputer', SimpleImputer(strategy='mean'), num_cols), \n",
    "     ('numerical_scaler', StandardScaler(), num_cols), \n",
    "     ('categorical_imputer', SimpleImputer(strategy='most_frequent'), cat_cols),\n",
    "     ('categorical_encoder', OneHotEncoder(handle_unknown='ignore'), cat_cols)])\n",
    "\n",
    "# transformer.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No! \n",
    "\n",
    "As we saw in the previous section, each step in `ColumnTransformer` is independent. Therefore, the input for the `OneHotEncoder()` is not the output of the `SimpleImputer(strategy='most_frequent')` but just a subset of the original DataFrame (`cat_cols`) which is not imputed. You cannot one-hot-encode a categorical variable that has missing data. \n",
    "\n",
    "We need something that can sequentially pass data throughout multiple feature engineering steps. Sequentially moving data... sounds familiar, right? Yes, you can do this with `Pipeline`! \n",
    "\n",
    "However, we need to create a feature engineering pipeline for numerical variables and categorical variables separately. So, we can come up with something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering pipeline for numerical variables \n",
    "num_pipeline= Pipeline([('imputer', SimpleImputer(strategy='mean')),\n",
    "                        ('scaler', StandardScaler())])\n",
    "\n",
    "# feature engineering pipeline for categorical variables \n",
    "cat_pipeline = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "                        ('encoder', OneHotEncoder(handle_unknown='ignore'))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think it as creating a 'new transformer' that combines multiple transformers for each type of variable. Doesn't it sounds cool? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=final></a>\n",
    "# 4. Final Pipeline\n",
    "\n",
    "Okay. Now that we have feature engineering pipelines defined for both numerical variables and categorical variables, we can put things together to train a Lasso model using `ColumnTransformer` and `Pipeline`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9483539967729575"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# put numerical and categorical feature engineering pipelines together\n",
    "preprocessor = ColumnTransformer([(\"num_pipeline\", num_pipeline, num_cols),\n",
    "                                  (\"cat_pipeline\", cat_pipeline, cat_cols)])\n",
    "\n",
    "\n",
    "# put transformers and an estimator together\n",
    "pipe = Pipeline([('preprocessing', preprocessor),\n",
    "                 ('lasso', Lasso(max_iter=10000))])  # increased max_iter to converge\n",
    "\n",
    "# fit model \n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very neat! We applied different sets of feature engineering steps to numercial and categorical variables and then trained a model in only a few lines of code. \n",
    "\n",
    "Thinking of how long and complex the code would be without `ColumnTransformer` and `Pipeline`, aren't you tempted to try this out right now? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=summary></a>\n",
    "# Summary \n",
    "\n",
    "In this post, we looked at how to combine feature engineering steps and a model fitting step together using `Pipeline` and `ColumnTransformer`. Especially we learned that we can use \n",
    "- `Pipeline` for combining transformers and an estimator \n",
    "- `ColumnTransformer` for applying different transformers to different columns \n",
    "- `Pipeline` for creating different feature engineering pipelines for numerical and categorical variables that sequentially apply a different set of transformers\n",
    "\n",
    "\n",
    "Also, check out the table below to recap the differences between `Pipeline` vs. `ColumnTransformer`:\n",
    "\n",
    "|   |    Pipeline | ColumnTransformer|\n",
    "|---|-------------|------------------|\n",
    "|Used for                   | Both transformers and estimator | Transformers only|\n",
    "|Main methods               | fit, transform, predict, score| fit, transform (no predict or score)|\n",
    "|Can pick columns to apply  | No | Yes|\n",
    "|Each step is performed     | Sequentially | Independently|\n",
    "|Transformed output columns | Same as input | May differ depending on the defined steps|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=References></a>\n",
    "# References \n",
    "- [Pipeline, ColumnTransformer and FeatureUnion explained](https://towardsdatascience.com/pipeline-columntransformer-and-featureunion-explained-f5491f815f)\n",
    "- [Feature Engineering for Machine Learning](https://www.udemy.com/course/feature-engineering-for-machine-learning/)\n",
    "- [sklearn Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\n",
    "- [sklearn ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-feature-engineering",
   "language": "python",
   "name": "venv-feature-engineering"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
